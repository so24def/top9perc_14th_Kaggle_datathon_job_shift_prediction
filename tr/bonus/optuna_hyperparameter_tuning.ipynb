{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38d2aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = [{'n_estimators': [300, 500, 1000, 2000],\n",
    "           'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [10, 20, 30, None],\n",
    "                'min_samples_split': [2, 5, 8, 13],\n",
    "               'min_samples_leaf': [2, 5, 8, 13],\n",
    "               'max_features': ['sqrt', 'log2', None],\n",
    "               'bootstrap': [True, False]\n",
    "           }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f96e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 50)\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 1000)\n",
    "    n_estimators =  trial.suggest_int('n_estimators', 100, 2000)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 21)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 21)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True,False])\n",
    "   \n",
    "    model = RandomForestClassifier(max_depth = max_depth, max_leaf_nodes = max_leaf_nodes,n_estimators = n_estimators,\n",
    "                                   min_samples_split= min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features, bootstrap=bootstrap,random_state=24)\n",
    "\n",
    "    \n",
    "    model.fit(x, y)    \n",
    "    scores = cross_val_score(model, x, y, cv=skf, n_jobs=-1, scoring=\"accuracy\",verbose=24,error_score='raise')\n",
    "    acc_mean = scores.mean()\n",
    "\n",
    "    return acc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72f1e5f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 23:35:06,884]\u001b[0m A new study created in memory with name: no-name-894f2a4e-a87c-429c-82ac-13b56abf1bcf\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   34.5s remaining:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   34.5s remaining:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.6s finished\n",
      "\u001b[32m[I 2023-02-21 23:36:09,125]\u001b[0m Trial 0 finished with value: 0.7101842374616172 and parameters: {'max_depth': 26, 'max_leaf_nodes': 227, 'n_estimators': 1184, 'min_samples_split': 19, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.7101842374616172.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 11.2min remaining: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 11.3min remaining:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 11.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 11.4min finished\n",
      "\u001b[32m[I 2023-02-21 23:56:45,813]\u001b[0m Trial 1 finished with value: 0.7412487205731833 and parameters: {'max_depth': 28, 'max_leaf_nodes': 498, 'n_estimators': 1599, 'min_samples_split': 9, 'min_samples_leaf': 16, 'max_features': None, 'bootstrap': True}. Best is trial 1 with value: 0.7412487205731833.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   11.8s remaining:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   11.8s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.9s finished\n",
      "\u001b[32m[I 2023-02-21 23:57:06,893]\u001b[0m Trial 2 finished with value: 0.7098771750255886 and parameters: {'max_depth': 38, 'max_leaf_nodes': 315, 'n_estimators': 494, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': False}. Best is trial 1 with value: 0.7412487205731833.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   11.5s remaining:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   11.5s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.6s finished\n",
      "\u001b[32m[I 2023-02-21 23:57:27,298]\u001b[0m Trial 3 finished with value: 0.6866939611054248 and parameters: {'max_depth': 38, 'max_leaf_nodes': 948, 'n_estimators': 639, 'min_samples_split': 17, 'min_samples_leaf': 18, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.7412487205731833.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.7min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.7min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n",
      "\u001b[32m[I 2023-02-22 00:00:26,503]\u001b[0m Trial 4 finished with value: 0.7662231320368476 and parameters: {'max_depth': 50, 'max_leaf_nodes': 786, 'n_estimators': 1826, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.7662231320368476.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   18.7s remaining:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   18.8s remaining:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   18.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   18.9s finished\n",
      "\u001b[32m[I 2023-02-22 00:00:59,976]\u001b[0m Trial 5 finished with value: 0.7264585465711362 and parameters: {'max_depth': 27, 'max_leaf_nodes': 613, 'n_estimators': 898, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.7662231320368476.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   30.0s remaining:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   30.1s remaining:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   30.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   30.2s finished\n",
      "\u001b[32m[I 2023-02-22 00:01:55,499]\u001b[0m Trial 6 finished with value: 0.7219549641760491 and parameters: {'max_depth': 33, 'max_leaf_nodes': 885, 'n_estimators': 1102, 'min_samples_split': 9, 'min_samples_leaf': 13, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.7662231320368476.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   14.3s remaining:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   14.4s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.4s finished\n",
      "\u001b[32m[I 2023-02-22 00:02:21,984]\u001b[0m Trial 7 finished with value: 0.7447799385875128 and parameters: {'max_depth': 32, 'max_leaf_nodes': 551, 'n_estimators': 381, 'min_samples_split': 18, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.7662231320368476.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   16.2s remaining:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   16.3s remaining:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.4s finished\n",
      "\u001b[32m[I 2023-02-22 00:02:53,123]\u001b[0m Trial 8 finished with value: 0.648157625383828 and parameters: {'max_depth': 6, 'max_leaf_nodes': 378, 'n_estimators': 1052, 'min_samples_split': 15, 'min_samples_leaf': 21, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.7662231320368476.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   19.0s remaining:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   19.1s remaining:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.1s finished\n",
      "\u001b[32m[I 2023-02-22 00:03:28,225]\u001b[0m Trial 9 finished with value: 0.6703172978505629 and parameters: {'max_depth': 9, 'max_leaf_nodes': 809, 'n_estimators': 1459, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.7662231320368476.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RF_study = optuna.create_study(direction='maximize')\n",
    "RF_study.optimize(RF_objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d36e22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7662231320368476\n",
      "Best hyperparameters: {'max_depth': 50, 'max_leaf_nodes': 786, 'n_estimators': 1826, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "trial = RF_study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
